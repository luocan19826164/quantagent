# .env 文件配置说明

## 当前配置

您的 `.env` 文件现在包含以下配置：

### OpenAI配置
```bash
OPENAI_API_KEY=sk-proj-...你的OpenAI密钥...
OPENAI_BASE_URL=https://api.openai.com/v1
MODEL_NAME=gpt-4o-mini
```

### DeepSeek配置（已添加）
```bash
DEEPSEEK_API_KEY=sk-7a588fe651c94a50aff17274f8d8144b
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
```

### Flask配置
```bash
SECRET_KEY=quant-agent-secret-key-2024
```

## 配置说明

### DeepSeek配置部分

```bash
# DeepSeek配置
DEEPSEEK_API_KEY=sk-7a588fe651c94a50aff17274f8d8144b  # DeepSeek的API密钥
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1          # DeepSeek的API地址
```

**作用**：
- `DEEPSEEK_API_KEY`: 用于调用DeepSeek API的密钥
- `DEEPSEEK_BASE_URL`: DeepSeek API的基础URL地址（通常不需要修改）

## 如何使用

### 1. 模型选择

在前端界面，模型下拉框现在有这些选项：

- **GPT-4o Mini** - 使用 OpenAI
- **GPT-4o** - 使用 OpenAI  
- **GPT-4 Turbo** - 使用 OpenAI
- **DeepSeek Chat** - 使用 DeepSeek
- **DeepSeek Coder** - 使用 DeepSeek

### 2. 切换模型

1. 在对话区右上角的模型选择器
2. 选择 "DeepSeek Chat" 或 "DeepSeek Coder"
3. 确认切换
4. 会话历史和上下文保持不变

### 3. 后端如何读取

当您切换模型时，后端会：

1. 从 `app.py` 的 `SUPPORTED_MODELS` 获取模型信息
2. 根据 `provider` 选择对应的环境变量：
   - `openai` → 读取 `OPENAI_API_KEY` 和 `OPENAI_BASE_URL`
   - `deepseek` → 读取 `DEEPSEEK_API_KEY` 和 `DEEPSEEK_BASE_URL`
3. 使用这些配置创建新的LLM实例

## 配置关系图

```
前端选择模型
    ↓
backend/app.py SUPPORTED_MODELS
    ↓
根据provider选择环境变量
    ↓
quant_agent.py switch_model()
    ↓
创建新的ChatOpenAI实例
    ↓
继续使用相同的memory和state
```

## 验证配置

### 1. 检查环境变量
```bash
cat .env
```

### 2. 启动应用测试
```bash
python backend/app.py
```

### 3. 访问界面
```
http://localhost:8080
```

### 4. 测试切换
- 先用 GPT-4o Mini 对话
- 切换到 DeepSeek Chat
- 继续对话，验证上下文保持

## 注意事项

1. **API密钥安全**：不要将`.env`文件提交到Git仓库
2. **DeepSeek额度**：注意免费额度使用情况
3. **网络问题**：如果DeepSeek访问慢，可以配置代理

## 如需修改配置

```bash
# 编辑.env文件
nano .env
# 或
open -e .env
```

修改后需要**重启应用**才能生效。
