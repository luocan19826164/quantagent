"""
Plan-Execute Agent ä¸»å¾ªç¯
æ ¸å¿ƒ Agent å®ç°ï¼Œè´Ÿè´£ä»»åŠ¡è§„åˆ’å’Œæ‰§è¡Œ

è¿™æ˜¯ Code Agent çš„å”¯ä¸€å…¥å£ï¼Œæ‰€æœ‰æ–‡ä»¶å˜æ›´å¿…é¡»é€šè¿‡å·¥å…·è°ƒç”¨å®Œæˆã€‚
"""

import os
import json
import logging
import threading
from typing import Dict, Any, List, Optional, Generator
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage

from .plan import Plan, PlanStep, PlanStatus, StepStatus, StepResult, PlanTracker, Planner, PlanStorage
from .tools import create_tool_registry, ToolRegistry, FunctionCallHandler, CREATE_PLAN_TOOL_NAME
from .workspace_manager import WorkspaceManager
from .context import (
    CodeContext, CodeAgentContext, ConversationHistory, 
    MemoryContext, ExecutionContext, OutputRecord
)
from .prompts.prompt_loader import get_code_agent_prompt_loader
from .events import (
    EventType,
    # åŸºç¡€äº‹ä»¶
    ErrorEvent, StatusEvent, FileChangeEvent, AnomalyDetectedEvent, ReplanWarningEvent,
    ResponseStartEvent, ResponseEndEvent,
    # è®¡åˆ’ç”Ÿå‘½å‘¨æœŸ
    PlanCreatedEvent,
    # è®¡åˆ’æ‰§è¡Œ
    PlanExecutionStartedEvent, PlanExecutionCompletedEvent,
    PlanExecutionFailedEvent, PlanExecutionCancelledEvent,
    # æ­¥éª¤
    StepStartedEvent, StepCompletedEvent, StepOutputEvent, StepErrorEvent,
    # å·¥å…·
    ToolCallsEvent, ToolResultEvent,
    # æ–‡ä»¶è¿è¡Œ
    FileRunStartedEvent, FileRunStdoutEvent, FileRunStderrEvent, FileRunExitEvent,
)
from utils.llm_config import resolve_llm_config


class PlanExecuteAgent:
    """
    Plan-Execute Agent
    
    è¿™æ˜¯ Code Agent çš„ç»Ÿä¸€å…¥å£ï¼Œæ ¸å¿ƒæµç¨‹ï¼š
    1. PLAN: ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
    2. EXECUTE: é€æ­¥æ‰§è¡Œï¼ˆæ‰€æœ‰æ“ä½œé€šè¿‡å·¥å…·è°ƒç”¨ï¼‰
    3. VERIFY: éªŒè¯ç»“æœ
    
    å®‰å…¨ä¿è¯ï¼š
    - æ‰€æœ‰æ–‡ä»¶å˜æ›´å¿…é¡»é€šè¿‡å·¥å…·è°ƒç”¨
    - æ­¥éª¤çº§æƒé™æ§åˆ¶
    - å¼‚å¸¸è¡Œä¸ºæ£€æµ‹
    """
    
    def __init__(self, user_id: int, project_id: str, use_sandbox: bool = False, 
                 llm_config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ– Agent
        
        Args:
            user_id: ç”¨æˆ·ID
            project_id: é¡¹ç›®ID
            use_sandbox: æ˜¯å¦ä½¿ç”¨ Docker æ²™ç®±æ‰§è¡Œï¼ˆé»˜è®¤ Falseï¼Œä»…åœ¨æœ‰ Docker æ—¶å¯ç”¨ï¼‰
            llm_config: å¯é€‰çš„ LLM é…ç½®ï¼Œå¦‚æœä¸ä¼ åˆ™ä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§
        """
        self.user_id = user_id
        self.project_id = project_id
        self.use_sandbox = use_sandbox
        
        # å·¥ä½œåŒºç®¡ç†
        self.workspace = WorkspaceManager(user_id)
        project = self.workspace.get_project(project_id)
        if not project:
            raise ValueError(f"Project not found: {project_id}")
        
        self.project_name = project["name"]
        self.project_path = self.workspace.get_project_path(project_id)
        
        # åˆå§‹åŒ– LLMï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„é…ç½®ï¼‰
        if llm_config is None:
            llm_config = resolve_llm_config("[CodeAgent]")
        else:
            logging.info(f"[CodeAgent] Using custom LLM config - Model: {llm_config.get('model')}")
        
        llm_kwargs = {
            "model": llm_config["model"],
            "temperature": 0.2,
            "api_key": llm_config["api_key"],
            "base_url": llm_config["base_url"],
            "streaming": True,  # å¯ç”¨æµå¼
        }
        if llm_config.get("extra_headers"):
            llm_kwargs["default_headers"] = llm_config["extra_headers"]
        
        self.llm = ChatOpenAI(**llm_kwargs)
        
        # å·¥å…·ç³»ç»Ÿï¼ˆå¸¦æ²™ç®±æ”¯æŒï¼‰
        self.tool_registry = create_tool_registry(
            self.project_path, 
            use_sandbox=use_sandbox,
            user_id=user_id,
            project_id=project_id
        )
        self.function_handler = FunctionCallHandler(self.tool_registry)
        
        # è®¡åˆ’ç³»ç»Ÿ
        self.planner = Planner(self.llm)
        self.tracker = PlanTracker()
        
        # ä»£ç ä¸Šä¸‹æ–‡ï¼ˆæ´»è·ƒæ–‡ä»¶è¿½è¸ªï¼‰
        self.code_context = CodeContext(
            workspace_root=self.project_path,
            max_files=10,
            max_content_per_file=5000
        )
        self._init_code_context()
        
        # è®¡åˆ’æŒä¹…åŒ–å­˜å‚¨
        plans_path = os.path.join(self.project_path, ".plans")
        self.plan_storage = PlanStorage(plans_path)
        
        # ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆæ–°å¢ï¼‰
        self.context = CodeAgentContext(
            session_id=f"{user_id}_{project_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            project_id=project_id,
            code_context=self.code_context,
            conversation=ConversationHistory(max_messages=50),
            memory=MemoryContext(),
            execution_context=ExecutionContext()
        )
        
        # ä¼šè¯çŠ¶æ€
        self.current_plan: Optional[Plan] = None
        
        # å°è¯•æ¢å¤æœªå®Œæˆçš„è®¡åˆ’
        self._try_restore_plan()
        
        # æ‰§è¡Œæ§åˆ¶
        self._cancel_flag = threading.Event()
        self._executing = False
        
        logging.info(f"PlanExecuteAgent initialized for user {user_id}, project {project_id}")
    
    def _try_restore_plan(self):
        """å°è¯•æ¢å¤æœªå®Œæˆçš„è®¡åˆ’"""
        if self.plan_storage.has_unfinished_plan():
            plan = self.plan_storage.load_current_plan()
            if plan:
                self.current_plan = plan
                self.tracker.set_plan(plan)
                logging.info(f"Restored unfinished plan: {plan.id}")
    
    def _init_code_context(self):
        """åˆå§‹åŒ–ä»£ç ä¸Šä¸‹æ–‡ï¼ŒåŠ è½½æ–‡ä»¶æ ‘"""
        try:
            file_tree = []
            for root, dirs, files in os.walk(self.project_path):
                # è·³è¿‡éšè—ç›®å½•å’Œç¼“å­˜ç›®å½•
                dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
                
                for f in files:
                    if f.startswith('.') or f.endswith('.pyc'):
                        continue
                    rel_path = os.path.relpath(os.path.join(root, f), self.project_path)
                    file_tree.append(rel_path)
            
            self.code_context.file_tree = sorted(file_tree)
            logging.info(f"Code context initialized with {len(file_tree)} files")
        except Exception as e:
            logging.warning(f"Failed to init code context: {e}")
    
    def _update_code_context(self, tool_name: str, tool_args: Dict, result: Any):
        """
        å·¥å…·è°ƒç”¨åæ›´æ–°ä»£ç ä¸Šä¸‹æ–‡
        
        Args:
            tool_name: å·¥å…·åç§°
            tool_args: å·¥å…·å‚æ•°
            result: å·¥å…·æ‰§è¡Œç»“æœ
        """
        if not result or not result.success:
            return
        
        try:
            if tool_name == "read_file":
                # è¯»å–æ–‡ä»¶åæ·»åŠ åˆ°æ´»è·ƒæ–‡ä»¶ï¼ˆéç¼–è¾‘çŠ¶æ€ï¼Œå¯æˆªæ–­ï¼‰
                path = tool_args.get("path", "")
                content = result.data.get("content", "") if result.data else ""
                self.code_context.add_file(path, content, is_editing=False)
                logging.info(f"Code context: Added file '{path}' ({len(content)} chars)")
                
            elif tool_name == "write_file":
                # å†™å…¥æ–‡ä»¶åæ›´æ–°æ´»è·ƒæ–‡ä»¶ï¼ˆæ ‡è®°ä¸ºç¼–è¾‘çŠ¶æ€ï¼Œä¿ç•™å®Œæ•´å†…å®¹ï¼‰
                path = tool_args.get("path", "")
                content = tool_args.get("content", "")
                self.code_context.add_file(path, content, is_editing=True)
                # æ›´æ–°æ–‡ä»¶æ ‘
                if path not in self.code_context.file_tree:
                    self.code_context.file_tree.append(path)
                    self.code_context.file_tree.sort()
                logging.info(f"Code context: Updated file '{path}' (editing)")
                
            elif tool_name == "patch_file":
                # patch åæ›´æ–°æ´»è·ƒæ–‡ä»¶ï¼ˆæ ‡è®°ä¸ºç¼–è¾‘çŠ¶æ€ï¼Œä¿ç•™å®Œæ•´å†…å®¹ï¼‰
                path = tool_args.get("path", "")
                new_content = result.data.get("new_content", "") if result.data else ""
                if new_content:
                    self.code_context.add_file(path, new_content, is_editing=True)
                    logging.info(f"Code context: Patched file '{path}' (editing)")
                    
            elif tool_name == "delete_file":
                # åˆ é™¤æ–‡ä»¶åä»ä¸Šä¸‹æ–‡ç§»é™¤
                path = tool_args.get("path", "")
                self.code_context.remove_file(path)
                if path in self.code_context.file_tree:
                    self.code_context.file_tree.remove(path)
                logging.info(f"Code context: Removed file '{path}'")
                
        except Exception as e:
            logging.warning(f"Failed to update code context: {e}")
    
    # ==================== å…¬å¼€ APIï¼ˆå…¼å®¹åŸ CodeAgentï¼‰====================
    
    def chat_stream(self, user_input: str) -> Generator[Dict[str, Any], None, None]:
        """
        æµå¼èŠå¤©æ¥å£ï¼ˆå…¼å®¹åŸ CodeAgent.chat_streamï¼‰
        
        LLM ä¼šè‡ªä¸»å†³å®šæ‰§è¡Œæ¨¡å¼ï¼ˆPlan æˆ– Directï¼‰ã€‚
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            
        Yields:
            äº‹ä»¶å­—å…¸:
            - {"type": "response_start", "mode": "plan"|"direct"}
            - {"type": "plan_created", "plan": {...}}  # ä»… Plan æ¨¡å¼
            - {"type": "step_started", "step_id": 1, ...}
            - {"type": "tool_result", ...}
            - {"type": "file_change", "path": "..."}
            - {"type": "response_end"}
            - {"type": "error", "message": "..."}
        """
        self._cancel_flag.clear()
        all_file_changes = []
        
        # è®°å½•ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        self.context.conversation.add_user_message(user_input)
        
        try:
            for event in self.run(user_input):
                event_type = event.get("type")
                
                # æ”¶é›†æ–‡ä»¶å˜æ›´
                if event_type == EventType.STEP_COMPLETED.value:
                    files = event.get("files_changed", [])
                    for f in files:
                        if f not in all_file_changes:
                            all_file_changes.append(f)
                            yield FileChangeEvent(path=f).to_dict()
                    yield event
                elif event_type == EventType.FILE_CHANGE.value:
                    path = event.get("path")
                    if path and path not in all_file_changes:
                        all_file_changes.append(path)
                    yield event
                elif event_type == EventType.PLAN_EXECUTION_COMPLETED.value:
                    # è¡¥å……æ–‡ä»¶å˜æ›´åˆ—è¡¨
                    event_file_changes = event.get("file_changes", [])
                    for f in event_file_changes:
                        if f not in all_file_changes:
                            all_file_changes.append(f)
                    yield PlanExecutionCompletedEvent(
                        plan=event.get("plan"),
                        message=event.get("message", ""),
                        summary=event.get("summary", ""),
                        success=event.get("success", True),
                        file_changes=all_file_changes
                    ).to_dict()
                elif event_type == EventType.ERROR.value:
                    yield ErrorEvent(error=event.get("error", "Unknown error")).to_dict()
                else:
                    # ç›´æ¥é€ä¼ å…¶ä»–äº‹ä»¶ï¼ˆåŒ…æ‹¬ response_start, response_endï¼‰
                    yield event
            
            # å‘é€å“åº”ç»“æŸäº‹ä»¶
            yield ResponseEndEvent().to_dict()
                    
        except Exception as e:
            logging.error(f"chat_stream error: {e}", exc_info=True)
            yield ErrorEvent(error=str(e)).to_dict()
            yield ResponseEndEvent().to_dict()
    
    def execute_file(self, file_path: str, timeout: str = "5min") -> Generator[Dict[str, Any], None, None]:
        """
        æ‰§è¡Œæ–‡ä»¶ï¼ˆæµå¼ï¼‰
        
        Args:
            file_path: ç›¸å¯¹äºé¡¹ç›®çš„æ–‡ä»¶è·¯å¾„
            timeout: è¶…æ—¶è®¾ç½®
            
        Yields:
            æ‰§è¡Œè¾“å‡ºäº‹ä»¶
        """
        # è§£æè¶…æ—¶
        timeout_seconds = self._parse_timeout(timeout)
        logging.info(f"[execute_file] Starting: {file_path}, timeout: {timeout_seconds}s")
        
        # å…ˆå‘é€å¼€å§‹äº‹ä»¶
        yield FileRunStartedEvent(file=file_path).to_dict()
        
        # ä½¿ç”¨ shell_exec å·¥å…·æ‰§è¡Œ
        result = self.tool_registry.execute(
            "shell_exec",
            command=f"python {file_path}",
            timeout=timeout_seconds
        )
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        logging.info(f"[execute_file] Result: success={result.success}, error={result.error}")
        if result.data:
            logging.info(f"[execute_file] Data keys: {list(result.data.keys())}")
            stdout = result.data.get("stdout", "")
            stderr = result.data.get("stderr", "")
            logging.info(f"[execute_file] stdout length: {len(stdout)}, stderr length: {len(stderr)}")
            if stdout:
                logging.info(f"[execute_file] stdout preview: {stdout[:200]}...")
        
        if result.success:
            if result.data and result.data.get("stdout"):
                yield FileRunStdoutEvent(content=result.data["stdout"]).to_dict()
            if result.data and result.data.get("stderr"):
                yield FileRunStderrEvent(content=result.data["stderr"]).to_dict()
            exit_code = result.data.get("exit_code", 0) if result.data else 0
            logging.info(f"[execute_file] Completed: exit_code={exit_code}")
            yield FileRunExitEvent(
                exit_code=exit_code,
                duration=result.data.get("duration", 0) if result.data else 0
            ).to_dict()
        else:
            logging.info(f"[execute_file] Failed: {result.error}")
            yield FileRunStderrEvent(content=result.error or "Execution failed").to_dict()
            yield FileRunExitEvent(
                exit_code=result.data.get("exit_code", 1) if result.data else 1,
                duration=result.data.get("duration", 0) if result.data else 0
            ).to_dict()
    
    def stop_execution(self) -> bool:
        """åœæ­¢æ‰§è¡Œ"""
        self._cancel_flag.set()
        return True
    
    def is_executing(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ‰§è¡Œ"""
        return self._executing
    
    def get_context_summary(self) -> Dict[str, Any]:
        """è·å–ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆå…¼å®¹åŸ CodeAgentï¼‰"""
        files = self.workspace.get_file_list(self.project_id)
        return {
            "project_id": self.project_id,
            "project_name": self.project_name,
            "file_count": len(files) if files else 0,
            "is_executing": self.is_executing(),
            "has_plan": self.current_plan is not None,
            "plan_status": self.current_plan.status.value if self.current_plan else None,
            # æ–°å¢ï¼šå®Œæ•´ä¸Šä¸‹æ–‡ä¿¡æ¯
            "context": self.context.to_dict() if self.context else None,
        }
    
    # ==================== æ ¸å¿ƒæ‰§è¡Œæµç¨‹ ====================
    
    def run(self, task: str) -> Generator[Dict[str, Any], None, None]:
        """
        æ‰§è¡Œä»»åŠ¡ï¼ˆæµå¼ï¼‰
        
        LLM è‡ªä¸»å†³å®šæ‰§è¡Œæ¨¡å¼ï¼š
        - å¦‚æœ LLM è°ƒç”¨ create_plan å·¥å…· â†’ Plan æ¨¡å¼ï¼ˆç”Ÿæˆè®¡åˆ’åé€æ­¥æ‰§è¡Œï¼‰
        - å¦‚æœ LLM ç›´æ¥è°ƒç”¨å…¶ä»–å·¥å…· â†’ Direct æ¨¡å¼ï¼ˆå·¥å…·è°ƒç”¨å¾ªç¯ï¼‰
        
        Args:
            task: ç”¨æˆ·ä»»åŠ¡æè¿°
            
        Yields:
            äº‹ä»¶å­—å…¸
        """
        self._executing = True
        self._cancel_flag.clear()
        
        try:
            yield StatusEvent(message="æ­£åœ¨åˆ†æä»»åŠ¡...").to_dict()
            
            # ========== ç¬¬ä¸€æ¬¡ LLM è°ƒç”¨ï¼šè®© LLM å†³å®šæ¨¡å¼ ==========
            messages = self._build_initial_messages(task)
            tool_definitions = self.tool_registry.get_all_definitions()
            
            response = self.llm.invoke(messages, tools=tool_definitions)
            
            # è§£æå·¥å…·è°ƒç”¨
            tool_calls = self.function_handler.parse_tool_calls(response)
            
            # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº† create_plan
            create_plan_call = None
            other_tool_calls = []
            
            for tc in tool_calls:
                if tc["name"] == CREATE_PLAN_TOOL_NAME:
                    create_plan_call = tc
                else:
                    other_tool_calls.append(tc)
            
            if create_plan_call:
                # ========== Plan æ¨¡å¼ï¼ˆå¤šæ­¥éª¤è®¡åˆ’ï¼‰==========
                logging.info(f"Agent: LLM chose Plan mode")
                yield from self._execute_plan_mode(task, create_plan_call, messages, response)
            else:
                # ========== Direct æ¨¡å¼ï¼ˆç»Ÿä¸€ä¸ºå•æ­¥éª¤ Planï¼‰==========
                logging.info(f"Agent: LLM chose Direct mode (converted to single-step plan)")
                yield from self._execute_direct_as_plan(task, response, messages, tool_calls)
            
        except Exception as e:
            logging.error(f"Agent run error: {e}", exc_info=True)
            yield ErrorEvent(error=str(e)).to_dict()
        finally:
            self._executing = False
    
    def _build_initial_messages(self, task: str) -> List:
        """
        æ„å»ºé¦–æ¬¡ LLM è°ƒç”¨çš„æ¶ˆæ¯ï¼ˆDirect å’Œ Plan æ¨¡å¼å…±ç”¨ï¼‰
        
        åŒ…å«ï¼š
        - ç³»ç»Ÿæç¤ºè¯ï¼ˆä» YAML åŠ è½½ï¼‰
        - æ¨¡å¼é€‰æ‹©æŒ‡å¯¼ï¼ˆä» YAML åŠ è½½ï¼‰
        - ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆè®°å¿†ã€è§„èŒƒã€æ´»è·ƒæ–‡ä»¶ã€Repo Mapï¼‰
        - å¯¹è¯å†å²ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        # åŠ è½½ç³»ç»Ÿæç¤ºè¯å’Œæ¨¡å¼é€‰æ‹©æŒ‡å¯¼ï¼ˆä» YAMLï¼‰
        prompt_loader = get_code_agent_prompt_loader()
        system_prompt = prompt_loader.get_system_prompt()
        mode_guidance = prompt_loader.get_mode_guidance()
        
        # æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆä¸åŒ…å«ä»£ç å®Œæ•´å†…å®¹ï¼Œé¿å…é¦–æ¬¡è°ƒç”¨ token è¿‡å¤šï¼‰
        context_summary = self._build_context_for_llm(
            include_conversation=False,
            include_code_content=False  # é¦–æ¬¡è°ƒç”¨ä¸åŒ…å«å®Œæ•´ä»£ç å†…å®¹
        )
        
        # ç»„è£…ç³»ç»Ÿæ¶ˆæ¯
        system_content = system_prompt
        if mode_guidance:
            system_content += f"\n\n{mode_guidance}"
        if context_summary:
            system_content += f"\n\n## å½“å‰ä¸Šä¸‹æ–‡\n{context_summary}"
        
        messages = [SystemMessage(content=system_content)]
        
        # æ·»åŠ å¯¹è¯å†å²ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.context.conversation and self.context.conversation.messages:
            # åªæ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²ï¼Œé¿å… token è¿‡å¤š
            recent_messages = self.context.conversation.get_recent_messages(n=10)
            if recent_messages:
                history = ConversationHistory(messages=recent_messages).to_langchain_messages()
                messages.extend(history)
                logging.info(f"Context: Added {len(recent_messages)} recent conversation messages")
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append(HumanMessage(content=task))
        
        return messages
    
    def _execute_plan_mode(self, task: str, create_plan_call: Dict, 
                           messages: List, initial_response) -> Generator[Dict[str, Any], None, None]:
        """æ‰§è¡Œ Plan æ¨¡å¼"""
        yield ResponseStartEvent(mode="plan").to_dict()
        
        # ä»å·¥å…·è°ƒç”¨ä¸­æå–è®¡åˆ’æ•°æ®
        plan_args = create_plan_call.get("arguments", {})
        analysis = plan_args.get("analysis", "")
        steps_data = plan_args.get("steps", [])
        
        # æ„å»º Plan å¯¹è±¡
        steps = []
        for i, step_data in enumerate(steps_data):
            steps.append(PlanStep(
                id=i + 1,
                description=step_data.get("description", ""),
                expected_outcome=step_data.get("expected_outcome", ""),
                tools_needed=step_data.get("tools", [])
            ))
        
        plan = Plan(
            task=task,
            steps=steps,
            status=PlanStatus.PLANNING
        )
        
        self.current_plan = plan
        self.tracker.set_plan(plan)
        
        # æŒä¹…åŒ–ä¿å­˜è®¡åˆ’
        self.plan_storage.save_plan(plan)
        
        yield PlanCreatedEvent(
            plan=plan.to_dict(),
            message=f"å·²ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œå…± {len(plan.steps)} ä¸ªæ­¥éª¤\n\nåˆ†æ: {analysis}"
        ).to_dict()
        
        # æ‰§è¡Œè®¡åˆ’
        yield from self._execute_plan(plan)
    
    def _execute_direct_as_plan(self, task: str, initial_response, 
                                messages: List, initial_tool_calls: List) -> Generator[Dict[str, Any], None, None]:
        """
        å°† Direct æ¨¡å¼è½¬æ¢ä¸ºå•æ­¥éª¤ Plan å¹¶æ‰§è¡Œ
        
        ç»Ÿä¸€æ‰§è¡Œæµç¨‹ï¼šDirect æ¨¡å¼ = å•æ­¥éª¤ Plan
        """
        yield ResponseStartEvent(mode="direct").to_dict()
        
        # åˆ›å»ºéšå¼å•æ­¥éª¤ Plan
        step = PlanStep(
            id=1,
            description=task,  # ç›´æ¥ç”¨ task ä½œä¸ºæ­¥éª¤æè¿°
            expected_outcome="å®Œæˆä»»åŠ¡",
            status=StepStatus.PENDING
        )
        
        plan = Plan(
            task=task,
            steps=[step],
            status=PlanStatus.PLANNING
        )
        
        self.current_plan = plan
        self.tracker.set_plan(plan)
        
        # Direct æ¨¡å¼ä¸å‘é€ PlanCreatedEventï¼ˆå› ä¸ºæ˜¯éšå¼çš„ï¼‰
        # ç›´æ¥å¼€å§‹æ‰§è¡Œ
        
        # æ‰§è¡Œè®¡åˆ’ï¼ˆå•æ­¥éª¤ï¼‰
        yield from self._execute_plan(plan, initial_response=initial_response, 
                                     initial_tool_calls=initial_tool_calls, 
                                     initial_messages=messages)
    
    def cancel_plan_execution(self) -> Dict[str, Any]:
        """å–æ¶ˆæ­£åœ¨æ‰§è¡Œçš„è®¡åˆ’"""
        if self.current_plan and self.current_plan.status == PlanStatus.EXECUTING:
            self._cancel_flag.set()
            self.current_plan.status = PlanStatus.CANCELLED
            return {"success": True, "message": "è®¡åˆ’æ‰§è¡Œå·²å–æ¶ˆ"}
        return {"success": False, "message": "æ²¡æœ‰æ­£åœ¨æ‰§è¡Œçš„è®¡åˆ’"}
    
    def _execute_plan(self, plan: Plan, 
                     initial_response=None, 
                     initial_tool_calls: List = None,
                     initial_messages: List = None) -> Generator[Dict[str, Any], None, None]:
        """
        æ‰§è¡Œè®¡åˆ’
        
        Args:
            plan: æ‰§è¡Œè®¡åˆ’
            initial_response: åˆå§‹ LLM å“åº”ï¼ˆDirect æ¨¡å¼éœ€è¦ï¼‰
            initial_tool_calls: åˆå§‹å·¥å…·è°ƒç”¨åˆ—è¡¨ï¼ˆDirect æ¨¡å¼éœ€è¦ï¼‰
            initial_messages: åˆå§‹æ¶ˆæ¯åˆ—è¡¨ï¼ˆDirect æ¨¡å¼éœ€è¦ï¼‰
        """
        plan.status = PlanStatus.EXECUTING
        
        yield PlanExecutionStartedEvent(
            plan=plan.to_dict(),
            message="å¼€å§‹æ‰§è¡Œè®¡åˆ’"
        ).to_dict()
        
        # é€æ­¥æ‰§è¡Œ
        for step_idx, step in enumerate(plan.steps):
            # æ£€æŸ¥å–æ¶ˆæ ‡å¿—
            if self._cancel_flag.is_set():
                plan.status = PlanStatus.CANCELLED
                yield PlanExecutionCancelledEvent(message="æ‰§è¡Œå·²å–æ¶ˆ").to_dict()
                return
            
            if plan.status == PlanStatus.CANCELLED:
                yield PlanExecutionCancelledEvent(message="æ‰§è¡Œå·²å–æ¶ˆ").to_dict()
                return
            
            # è·³è¿‡å·²å®Œæˆçš„æ­¥éª¤
            if step.status in (StepStatus.DONE, StepStatus.SKIPPED):
                continue
            
            # æ‰§è¡Œæ­¥éª¤
            # å¦‚æœæ˜¯ Direct æ¨¡å¼ï¼ˆå•æ­¥éª¤ Planï¼‰ä¸”æ˜¯ç¬¬ä¸€æ­¥ï¼Œä¼ å…¥åˆå§‹å“åº”
            is_direct_mode = (len(plan.steps) == 1 and initial_response is not None)
            yield from self._execute_step(
                step, plan,
                initial_response=initial_response if (is_direct_mode and step_idx == 0) else None,
                initial_tool_calls=initial_tool_calls if (is_direct_mode and step_idx == 0) else None,
                initial_messages=initial_messages if (is_direct_mode and step_idx == 0) else None
            )
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’ï¼ˆä»…è­¦å‘Šï¼Œä¸ä¸­æ–­æ‰§è¡Œï¼‰
            if self.tracker.should_replan():
                yield ReplanWarningEvent(message="æ£€æµ‹åˆ°æ‰§è¡Œé—®é¢˜ï¼Œå¯èƒ½éœ€è¦å…³æ³¨").to_dict()
                # é‡ç½®å¼‚å¸¸è®¡æ•°ï¼Œç»§ç»­æ‰§è¡Œ
                self.tracker.anomaly_count = 0
                # æ³¨æ„ï¼šè¿™é‡Œä¸å† breakï¼Œç»§ç»­æ‰§è¡Œå‰©ä½™æ­¥éª¤
            
            # æ£€æŸ¥æ­¥éª¤æ˜¯å¦å¤±è´¥
            if step.status == StepStatus.FAILED:
                plan.status = PlanStatus.FAILED
                yield PlanExecutionFailedEvent(
                    step_id=step.id,
                    error=step.error,
                    message=f"Step {step.id} æ‰§è¡Œå¤±è´¥"
                ).to_dict()
                return
        
        # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å®Œæˆ
        if plan.is_complete():
            plan.status = PlanStatus.COMPLETED
            # å½’æ¡£å·²å®Œæˆçš„è®¡åˆ’
            self.plan_storage.archive_plan(plan)
            summary = self._generate_summary(plan)
            
            # åˆ¤æ–­æ˜¯å¦ä¸º Direct æ¨¡å¼ï¼ˆå•æ­¥éª¤ Planï¼‰
            is_direct_mode = (len(plan.steps) == 1)
            
            # è®°å½•æ‰§è¡Œå†³ç­–åˆ° MemoryContext
            if is_direct_mode:
                # Direct æ¨¡å¼ï¼šè®°å½•ä¸º Direct æ¨¡å¼å®Œæˆ
                all_file_changes = []
                for step in plan.steps:
                    all_file_changes.extend(step.files_changed)
                if all_file_changes:
                    self.context.memory.add_decision(
                        decision=f"Direct æ¨¡å¼å®Œæˆ: {plan.task[:50]}...",
                        reason=f"ä¿®æ”¹äº†æ–‡ä»¶: {', '.join(all_file_changes[:5])}"
                    )
            else:
                # Plan æ¨¡å¼ï¼šè®°å½•ä¸ºè®¡åˆ’å®Œæˆ
                self.context.memory.add_decision(
                    decision=f"å®Œæˆä»»åŠ¡: {plan.task}",
                    reason=summary
                )
            
            # è®¡ç®—æ–‡ä»¶å˜æ›´
            all_file_changes = []
            for step in plan.steps:
                all_file_changes.extend(step.files_changed)
            
            # Direct æ¨¡å¼ï¼šè®¡ç®—è¿­ä»£æ¬¡æ•°ï¼ˆé€šè¿‡ tool_calls æ•°é‡ä¼°ç®—ï¼‰
            if is_direct_mode and plan.steps[0].tool_calls:
                iteration_count = len([tc for tc in plan.steps[0].tool_calls if isinstance(tc, dict)])
                direct_summary = f"Direct æ¨¡å¼æ‰§è¡Œå®Œæˆï¼Œå…± {iteration_count} è½®å¯¹è¯"
            else:
                direct_summary = summary
            
            yield PlanExecutionCompletedEvent(
                plan=plan.to_dict(),
                message="æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆ" if not is_direct_mode else "ä»»åŠ¡å®Œæˆ",
                summary=direct_summary if is_direct_mode else summary,
                success=True,
                file_changes=list(set(all_file_changes))
            ).to_dict()
        elif plan.has_failed():
            plan.status = PlanStatus.FAILED
            # ä¿å­˜å¤±è´¥çŠ¶æ€
            self.plan_storage.save_plan(plan)
            
            # è®°å½•å¤±è´¥åˆ° MemoryContext
            self.context.memory.add_decision(
                decision=f"ä»»åŠ¡å¤±è´¥: {plan.task}",
                reason="éƒ¨åˆ†æ­¥éª¤æ‰§è¡Œå¤±è´¥"
            )
            
            yield PlanExecutionFailedEvent(
                plan=plan.to_dict(),
                message="éƒ¨åˆ†æ­¥éª¤æ‰§è¡Œå¤±è´¥"
            ).to_dict()
    
    def _execute_step(self, step: PlanStep, plan: Plan,
                     initial_response=None,
                     initial_tool_calls: List = None,
                     initial_messages: List = None) -> Generator[Dict[str, Any], None, None]:
        """
        æ‰§è¡Œå•ä¸ªæ­¥éª¤
        
        Args:
            step: è®¡åˆ’æ­¥éª¤
            plan: æ‰§è¡Œè®¡åˆ’
            initial_response: åˆå§‹ LLM å“åº”ï¼ˆDirect æ¨¡å¼éœ€è¦ï¼‰
            initial_tool_calls: åˆå§‹å·¥å…·è°ƒç”¨åˆ—è¡¨ï¼ˆDirect æ¨¡å¼éœ€è¦ï¼‰
            initial_messages: åˆå§‹æ¶ˆæ¯åˆ—è¡¨ï¼ˆDirect æ¨¡å¼éœ€è¦ï¼‰
        """
        self.tracker.start_step(step.id)
        
        yield StepStartedEvent(
            step_id=step.id,
            description=step.description,
            progress=plan.get_progress()
        ).to_dict()
        
        try:
            # æ„å»ºæ­¥éª¤æ‰§è¡Œæ¶ˆæ¯
            is_direct_mode = (initial_response is not None)
            if is_direct_mode:
                # Direct æ¨¡å¼ï¼šä½¿ç”¨åˆå§‹æ¶ˆæ¯ï¼ˆå·²ç»åŒ…å«å¯¹è¯å†å²ï¼‰
                messages = initial_messages.copy() if initial_messages else []
            else:
                # Plan æ¨¡å¼ï¼šæ„å»ºæ­¥éª¤æ¶ˆæ¯
                messages = self._build_step_messages(step, plan)
            
            # å·¥å…·è°ƒç”¨å¾ªç¯
            max_iterations = 15 if is_direct_mode else 10  # Direct æ¨¡å¼å…è®¸æ›´å¤šè¿­ä»£
            iteration = 0
            step_response = ""
            all_tool_calls = []
            all_files_changed = []
            
            # Direct æ¨¡å¼ï¼šå…ˆå¤„ç†åˆå§‹å·¥å…·è°ƒç”¨
            if is_direct_mode and initial_tool_calls:
                current_response = initial_response
                current_tool_calls = initial_tool_calls
                # è¿‡æ»¤æ‰ create_planï¼ˆDirect æ¨¡å¼ä¸­ä¸åº”è¯¥è°ƒç”¨ï¼‰
                current_tool_calls = [tc for tc in current_tool_calls if tc["name"] != CREATE_PLAN_TOOL_NAME]
            else:
                current_response = None
                current_tool_calls = None
            
            while iteration < max_iterations:
                # æ£€æŸ¥å–æ¶ˆæ ‡å¿—
                if self._cancel_flag.is_set():
                    step.status = StepStatus.FAILED
                    step.error = "æ‰§è¡Œè¢«å–æ¶ˆ"
                    return
                
                iteration += 1
                logging.info(f"Step {step.id} iteration {iteration}")
                
                # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿­ä»£ä¸”æ˜¯ Direct æ¨¡å¼ï¼Œä½¿ç”¨åˆå§‹å“åº”
                if iteration == 1 and is_direct_mode and current_response is not None:
                    response = current_response
                    response_content = response.content or ""
                else:
                    # è·å–å¯ç”¨å·¥å…·å®šä¹‰
                    tool_definitions = self.tool_registry.get_all_definitions()
                    logging.debug(f"Available tools: {[t['function']['name'] for t in tool_definitions]}")
                    
                    # è°ƒç”¨ LLMï¼ˆä½¿ç”¨ invoke ç¡®ä¿å·¥å…·è°ƒç”¨è¢«æ­£ç¡®è·å–ï¼‰
                    # æµå¼æ¨¡å¼ä¸‹å·¥å…·è°ƒç”¨å¯èƒ½æ— æ³•æ­£ç¡®è§£æï¼Œæ”¹ç”¨éæµå¼è°ƒç”¨
                    response = self.llm.invoke(
                        messages,
                        tools=tool_definitions
                    )
                    
                    response_content = response.content or ""
                    current_response = response
                
                # è¾“å‡º LLM å“åº”å†…å®¹
                if response_content:
                    step_response += response_content + "\n"
                    yield StepOutputEvent(
                        step_id=step.id,
                        content=response_content
                    ).to_dict()
                    logging.info(f"Step {step.id}: LLM response: {response_content[:200]}...")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if iteration == 1 and is_direct_mode and current_tool_calls is not None:
                    # Direct æ¨¡å¼ç¬¬ä¸€æ¬¡è¿­ä»£ï¼šä½¿ç”¨åˆå§‹å·¥å…·è°ƒç”¨
                    tool_calls = current_tool_calls
                else:
                    tool_calls = self.function_handler.parse_tool_calls(response)
                    current_tool_calls = tool_calls
                
                if tool_calls:
                    logging.info(f"Step {step.id}: Found {len(tool_calls)} tool calls: {[tc['name'] for tc in tool_calls]}")
                else:
                    logging.info(f"Step {step.id}: No tool calls, step complete")
                
                if not tool_calls:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæ­¥éª¤å®Œæˆ
                    break
                
                # Direct æ¨¡å¼ï¼šè¿‡æ»¤æ‰ create_planï¼ˆä¸åº”è¯¥åœ¨ Direct æ¨¡å¼ä¸­è°ƒç”¨ï¼‰
                if is_direct_mode:
                    tool_calls = [tc for tc in tool_calls if tc["name"] != CREATE_PLAN_TOOL_NAME]
                    if not tool_calls:
                        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæ­¥éª¤å®Œæˆ
                        break
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                yield ToolCallsEvent(
                    step_id=step.id,
                    calls=[{"name": tc["name"], "arguments": tc["arguments"]} for tc in tool_calls]
                ).to_dict()
                
                for tc in tool_calls:
                    logging.info(f"  ğŸ”§ Tool: {tc['name']} args: {str(tc['arguments'])[:100]}")
                
                tool_results = self.function_handler.execute_tool_calls(tool_calls)
                all_tool_calls.extend(tool_results)
                
                # æå–å˜æ›´çš„æ–‡ä»¶
                changed_files = self.function_handler.extract_changed_files(tool_results)
                all_files_changed.extend(changed_files)
                
                if changed_files:
                    logging.info(f"  ğŸ“ Files changed: {changed_files}")
                
                # è®°å½• assistant æ¶ˆæ¯ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰
                self.context.conversation.add_assistant_message(
                    content=response_content or "",
                    tool_calls=[{"id": tc["id"], "name": tc["name"], "args": tc["arguments"]} for tc in tool_calls]
                )
                
                # è¾“å‡ºå·¥å…·ç»“æœå¹¶æ›´æ–°ä»£ç ä¸Šä¸‹æ–‡
                for tr in tool_results:
                    result = tr["result"]
                    status = "âœ…" if result.success else "âŒ"
                    logging.info(f"  {status} {tr['name']}: success={result.success}, error={result.error}")
                    
                    # æ›´æ–°ä»£ç ä¸Šä¸‹æ–‡ï¼ˆæ´»è·ƒæ–‡ä»¶ï¼‰
                    self._update_code_context(tr["name"], tr["arguments"], result)
                    
                    # è®°å½•å·¥å…·ç»“æœåˆ°å¯¹è¯å†å²
                    file_path = tr["arguments"].get("path") or tr["arguments"].get("file_path")
                    self.context.conversation.add_tool_result(
                        tool_call_id=tr["tool_call_id"],
                        tool_name=tr["name"],
                        result=result.to_message()[:500],  # æˆªæ–­ï¼Œå®Œæ•´å†…å®¹åœ¨ focused_files ä¸­
                        file_path=file_path
                    )
                    
                    yield ToolResultEvent(
                        step_id=step.id,
                        tool=tr["name"],
                        success=result.success,
                        output=result.output[:500] if result.output else "",
                        error=result.error
                    ).to_dict()
                
                # å¼‚å¸¸æ£€æµ‹ï¼ˆPlan æ¨¡å¼æ‰æœ‰ï¼ŒDirect æ¨¡å¼è·³è¿‡ï¼‰
                if not is_direct_mode:
                    anomaly = self.tracker.detect_anomaly(step_response, tool_calls)
                    if anomaly:
                        yield AnomalyDetectedEvent(
                            step_id=step.id,
                            anomaly=anomaly
                        ).to_dict()
                        # æ·»åŠ ä¿®æ­£æç¤º
                        correction = self.tracker.get_correction_prompt(anomaly)
                        messages.append(HumanMessage(content=correction))
                
                # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯
                # LangChain AIMessage æœŸæœ›çš„ tool_calls æ ¼å¼: {"id": str, "name": str, "args": dict}
                messages.append(AIMessage(
                    content=response_content or "",
                    tool_calls=[{
                        "id": tc["id"],
                        "name": tc["name"],
                        "args": tc["arguments"]
                    } for tc in tool_calls]
                ))
                
                for tr in tool_results:
                    messages.append(ToolMessage(
                        content=tr["result"].to_message(),
                        tool_call_id=tr["tool_call_id"]
                    ))
            
            # æ­¥éª¤å®Œæˆ
            result = StepResult(
                success=True,
                response=step_response,
                files_changed=list(set(all_files_changed)),
                tool_calls=[{"name": tc["name"], "arguments": tc.get("arguments", {})} for tc in all_tool_calls]
            )
            
            self.tracker.complete_step(step.id, result)
            
            # æŒä¹…åŒ–æ›´æ–°æ­¥éª¤çŠ¶æ€
            self.plan_storage.update_step_status(
                plan.id, step.id, StepStatus.DONE, result
            )
            
            yield StepCompletedEvent(
                step_id=step.id,
                files_changed=result.files_changed,
                progress=plan.get_progress()
            ).to_dict()
            
        except Exception as e:
            logging.error(f"Step {step.id} execution error: {e}", exc_info=True)
            self.tracker.fail_step(step.id, str(e))
            yield StepErrorEvent(
                step_id=step.id,
                error=str(e)
            ).to_dict()
    

    
    def _build_step_messages(self, step: PlanStep, plan: Plan) -> List:
        """
        æ„å»ºæ­¥éª¤æ‰§è¡Œæ¶ˆæ¯ï¼ˆPlan æ¨¡å¼ï¼‰
        
        ä½¿ç”¨ç»Ÿä¸€çš„ä¸Šä¸‹æ–‡æ„å»ºæ–¹æ³•ï¼Œä¸ Direct æ¨¡å¼ä¿æŒä¸€è‡´ã€‚
        """
        prompt_loader = get_code_agent_prompt_loader()
        
        # 1. åŸºç¡€ç³»ç»Ÿæç¤ºè¯ï¼ˆPlan æ¨¡å¼ç‰¹æœ‰ï¼‰
        step_execution_prompt = prompt_loader.get_step_execution_prompt()
        
        # 2. é¡¹ç›®ä¸Šä¸‹æ–‡ï¼ˆPlan æ¨¡å¼ç‰¹æœ‰ï¼‰
        project_context_template = prompt_loader.get_project_context()
        project_context = project_context_template.format(
            project_name=self.project_name,
            project_path=self.project_path,
            tools_description=self._format_tools_description()
        )
        
        # 3. ç»Ÿä¸€çš„ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆåŒ…å«ä»£ç å®Œæ•´å†…å®¹ï¼ŒPlan æ¨¡å¼éœ€è¦ï¼‰
        context_summary = self._build_context_for_llm(
            include_conversation=False,  # å¯¹è¯å†å²å•ç‹¬æ·»åŠ 
            include_code_content=True    # Plan æ¨¡å¼éœ€è¦å®Œæ•´ä»£ç å†…å®¹
        )
        
        # ç»„è£…ç³»ç»Ÿæ¶ˆæ¯
        system_template = prompt_loader.get_step_system_message()
        final_system_content = system_template.format(
            step_execution_prompt=step_execution_prompt,
            project_context=project_context,
            active_files_warning="",  # å·²åŒ…å«åœ¨ context_summary ä¸­
            code_context=context_summary if context_summary else ""
        )
        
        messages = [SystemMessage(content=final_system_content)]
        
        # 4. æ·»åŠ å¯¹è¯å†å²ï¼ˆç»Ÿä¸€å¤„ç†ï¼Œä¸ Direct æ¨¡å¼ä¸€è‡´ï¼‰
        if self.context.conversation and self.context.conversation.messages:
            # åªæ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²ï¼Œé¿å… token è¿‡å¤š
            recent_messages = self.context.conversation.get_recent_messages(n=10)
            if recent_messages:
                history = ConversationHistory(messages=recent_messages).to_langchain_messages()
                messages.extend(history)
                logging.info(f"Context: Added {len(recent_messages)} recent conversation messages to step {step.id}")
        
        # 5. ç”¨æˆ·æ¶ˆæ¯ï¼ˆå½“å‰æ­¥éª¤ï¼‰
        user_message_template = prompt_loader.get_step_user_message()
        user_message = user_message_template.format(
            task=plan.task,
            plan_summary=plan.to_summary(),
            step_id=step.id,
            total_steps=len(plan.steps),
            step_description=step.description,
            expected_outcome=step.expected_outcome or "å®Œæˆè¯¥æ­¥éª¤çš„æ“ä½œ"
        )
        messages.append(HumanMessage(content=user_message))
        
        return messages
    
    
    def _build_context_for_llm(self, include_conversation: bool = False, 
                                include_code_content: bool = True) -> str:
        """
        æ„å»ºå‘é€ç»™ LLM çš„ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆç»Ÿä¸€æ–¹æ³•ï¼ŒDirect å’Œ Plan æ¨¡å¼å…±ç”¨ï¼‰
        
        æ‰€æœ‰æ ¼å¼åŒ–æ–‡æœ¬éƒ½ä» YAML æ¨¡æ¿åŠ è½½ï¼Œä»£ç åªè´Ÿè´£æ•°æ®å¡«å……ã€‚
        
        Args:
            include_conversation: æ˜¯å¦åŒ…å«å¯¹è¯å†å²ï¼ˆé€šå¸¸é€šè¿‡ messages å•ç‹¬æ·»åŠ ï¼‰
            include_code_content: æ˜¯å¦åŒ…å«ä»£ç æ–‡ä»¶å®Œæ•´å†…å®¹ï¼ˆPlan æ¨¡å¼éœ€è¦ï¼ŒDirect æ¨¡å¼å¯é€‰ï¼‰
        
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        prompt_loader = get_code_agent_prompt_loader()
        parts = []
        
        # 1. è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆå†å²å†³ç­–ï¼‰- é«˜ä¼˜å…ˆçº§
        if self.context.memory and self.context.memory.decisions:
            recent_decisions = self.context.memory.decisions[-5:]  # æœ€è¿‘ 5 æ¡
            if recent_decisions:
                decisions_list = "\n".join(f"- **{d.decision}**: {d.reason}" for d in recent_decisions)
                template = prompt_loader.get_context_history_decisions()
                parts.append(template.format(decisions_list=decisions_list))
                parts.append("")  # ç©ºè¡Œåˆ†éš”
        
        # 2. é¡¹ç›®è§„èŒƒ
        if self.context.memory and self.context.memory.project_conventions:
            recent_conventions = self.context.memory.project_conventions[-5:]  # æœ€è¿‘ 5 æ¡
            if recent_conventions:
                conventions_list = "\n".join(f"- {conv}" for conv in recent_conventions)
                template = prompt_loader.get_context_project_conventions()
                parts.append(template.format(conventions_list=conventions_list))
                parts.append("")
        
        # 3. æ´»è·ƒæ–‡ä»¶åˆ—è¡¨ï¼ˆæ‰€æœ‰æ¨¡å¼éƒ½éœ€è¦ï¼‰
        if self.context.code_context and self.context.code_context.focused_files:
            files = [f.path for f in self.context.code_context.focused_files]
            editing_count = sum(1 for f in self.context.code_context.focused_files if f.is_editing)
            
            # æ„å»ºæ–‡ä»¶åˆ—è¡¨ï¼ˆåªæå–æ•°æ®ï¼Œä¸åŒ…å«æç¤ºæ–‡æœ¬ï¼‰
            file_list = "\n".join(f"- {path}" for path in files[:15])  # æœ€å¤šæ˜¾ç¤º 15 ä¸ª
            
            # ä½¿ç”¨ YAML æ¨¡æ¿æ ¼å¼åŒ–ç¼–è¾‘ä¿¡æ¯å’Œæ›´å¤šæ–‡ä»¶ä¿¡æ¯ï¼ˆä¸ç¡¬ç¼–ç æ–‡æœ¬ï¼‰
            editing_info = ""
            if editing_count > 0:
                editing_template = prompt_loader.get_context_editing_info()
                editing_info = editing_template.format(editing_count=editing_count) + "\n"
            
            more_files_info = ""
            if len(files) > 15:
                more_files_template = prompt_loader.get_context_more_files_info()
                more_files_info = more_files_template.format(more_files_count=len(files) - 15)
            
            template = prompt_loader.get_context_active_files()
            parts.append(template.format(
                file_count=len(files),
                editing_info=editing_info,
                file_list=file_list,
                more_files_info=more_files_info
            ))
            parts.append("")
        
        # 4. ç¬¦å·ç´¢å¼•ï¼ˆRepo Mapï¼‰- å¸®åŠ©å¿«é€Ÿäº†è§£é¡¹ç›®ç»“æ„
        if (self.context.code_context and 
            self.context.code_context.symbol_index and
            self.context.code_context.symbol_index.file_symbols):
            repo_map = self.context.code_context.symbol_index.to_repo_map_string(max_files=20)
            if repo_map:
                template = prompt_loader.get_context_repo_map()
                parts.append(template.format(repo_map_content=repo_map))
                parts.append("")
        
        # 5. ä»£ç æ–‡ä»¶å®Œæ•´å†…å®¹ï¼ˆPlan æ¨¡å¼éœ€è¦ï¼ŒDirect æ¨¡å¼å¯é€‰ï¼‰
        if include_code_content and self.context.code_context:
            active_files_context = self.context.code_context.to_context_string()
            if active_files_context:
                template = prompt_loader.get_context_file_content()
                parts.append(template.format(file_content=active_files_context))
                logging.info(f"Context: Including {len(self.context.code_context.focused_files)} active files content")
        
        return "\n".join(parts) if parts else ""
    
    def _format_tools_description(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·æè¿°"""
        tools = self.tool_registry.list_tools()
        return "\n".join(f"- {t}" for t in tools)
    
    def _generate_summary(self, plan: Plan) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ€»ç»“"""
        completed = [s for s in plan.steps if s.status == StepStatus.DONE]
        files_changed = set()
        for s in completed:
            files_changed.update(s.files_changed)
        
        summary_parts = [
            f"ä»»åŠ¡: {plan.task}",
            f"å®Œæˆæ­¥éª¤: {len(completed)}/{len(plan.steps)}",
        ]
        
        if files_changed:
            summary_parts.append(f"ä¿®æ”¹æ–‡ä»¶: {', '.join(files_changed)}")
        
        return "\n".join(summary_parts)
    
    def _parse_timeout(self, timeout: str) -> int:
        """è§£æè¶…æ—¶å­—ç¬¦ä¸²"""
        timeout = timeout.lower().strip()
        if timeout.endswith("min"):
            return int(timeout[:-3]) * 60
        elif timeout.endswith("s"):
            return int(timeout[:-1])
        elif timeout.endswith("h"):
            return int(timeout[:-1]) * 3600
        else:
            return int(timeout)
